{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np \n",
    "from tqdm import trange # Processing Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment settings\n",
    "gamma = 0.9 # discount factor\n",
    "epsilon=0.2 # exploration parameter\n",
    "n_episodes = 4000  # number of training episodes\n",
    "seed = 41684 \n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.9\n",
    "epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = south, 1 = north, 2 = east, 3 = west, 4 = pickup, 5 = dropoff\n",
    "env = gym.make(\"Taxi-v2\").env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 states\n",
      "6 actions\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_states, n_actions = env.observation_space.n, env.action_space.n\n",
    "print('{} states'.format(n_states))\n",
    "print('{} actions'.format(n_actions))\n",
    "env.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the agent’s Q-table to zeros\n",
    "def init_q(s, a):\n",
    "    \"\"\"\n",
    "    s: number of states\n",
    "    a: number of actions\n",
    "    \"\"\"\n",
    "    return np.zeros((s, a))\n",
    "\n",
    "# epsilon-greedy exploration strategy\n",
    "def epsilon_greedy(Q, epsilon, n_actions, s):\n",
    "    \"\"\"\n",
    "    Q: Q Table\n",
    "    epsilon: exploration parameter\n",
    "    n_actions: number of actions\n",
    "    s: state\n",
    "    \"\"\"\n",
    "    # selects a random action with probability epsilon\n",
    "    if np.random.random() <= epsilon:\n",
    "        return np.random.randint(n_actions)\n",
    "    else:\n",
    "        return np.argmax(Q[s, :])\n",
    "    \n",
    "# SARSA Process\n",
    "def q_learning(alpha, gamma, epsilon, n_episodes):\n",
    "    \"\"\"\n",
    "    alpha: learning rate\n",
    "    gamma: exploration parameter\n",
    "    n_episodes: number of episodes\n",
    "    \"\"\"\n",
    "    # initialize Q table\n",
    "    Q = init_q(n_states, n_actions)\n",
    "    t = trange(n_episodes)\n",
    "    for i in t:\n",
    "        # initial state\n",
    "        s = env.reset() \n",
    "        done = False\n",
    "        while not done:\n",
    "            a = epsilon_greedy(Q, epsilon, n_actions, s)\n",
    "            s_, reward, done, _ = env.step(a)\n",
    "            # update Q table\n",
    "            Q[s, a] += alpha * (reward + (gamma * max(Q[s_,:])) - Q[s, a])\n",
    "            if done:\n",
    "                break\n",
    "            s= s_\n",
    "    env.close()\n",
    "    return Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [04:05<00:00, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.0\n",
      "n_episodes:  4000\n",
      "Q(462,4):  -11.374402515013\n",
      "Q(398,3):  4.348907000000002\n",
      "Q(253,0):  -0.5856821172999982\n",
      "Q(377,1):  9.683000000000002\n",
      "Q(83,5):  -12.82326603716053\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "\n",
    "Q = q_learning(alpha, gamma, epsilon, n_episodes)\n",
    "\n",
    "print(\"alpha: \", alpha)\n",
    "print(\"n_episodes: \", n_episodes)\n",
    "print(\"Q(462,4): \",Q[462,4])   \n",
    "print(\"Q(398,3): \",Q[398,3])   \n",
    "print(\"Q(253,0): \",Q[253,0])   \n",
    "print(\"Q(377,1): \",Q[377,1])   \n",
    "print(\"Q(83,5): \",Q[83,5])  \n",
    "print(\"------------------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(421,2):  -3.1369622635116987\n",
      "Q(126,0):  -3.8232660371605287\n",
      "Q(343,1):  -2.3744025150129984\n",
      "Q(11,3):  -2.3744025150129984\n",
      "Q(444,4):  -12.136962263511698\n",
      "Q(496,1):  2.9140163000000023\n",
      "Q(257,0):  5.9432300000000025\n",
      "Q(222,2):  0.46035320300000193\n",
      "Q(391,3):  -3.8232660371605287\n",
      "Q(82,5):  -10.527113905569998\n"
     ]
    }
   ],
   "source": [
    "print(\"Q(421,2): \",Q[421,2])   \n",
    "print(\"Q(126,0): \",Q[126,0])   \n",
    "print(\"Q(343,1): \",Q[343,1])\n",
    "print(\"Q(11,3): \",Q[11,3])\n",
    "print(\"Q(444,4): \",Q[444,4])   \n",
    "print(\"Q(496,1): \",Q[496,1])  \n",
    "print(\"Q(257,0): \",Q[257,0])   \n",
    "print(\"Q(222,2): \",Q[222,2])   \n",
    "print(\"Q(391,3): \",Q[391,3])   \n",
    "print(\"Q(82,5): \",Q[82,5])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
